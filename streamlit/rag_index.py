# rag_index.py
"""
products_all_ver1.json â†’ Chroma VectorDB ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸

- í•œ ìƒí’ˆë‹¹ í•˜ë‚˜ì˜ document
- ë¬´ë“œ í‚¤ì›Œë“œ / ì¹´í…Œê³ ë¦¬ / ê°€ê²© / ë¸Œëžœë“œ ë“± ë©”íƒ€ë°ì´í„° ì €ìž¥
"""

import json
from pathlib import Path
from typing import List, Dict, Any

import chromadb
from sentence_transformers import SentenceTransformer

from config import (
    PRODUCTS_JSON_PATH,
    VECTOR_DB_DIR,
    EMBEDDING_MODEL_NAME,
)

def build_index():
    print("â–¶ RAG ì¸ë±ì‹± ì‹œìž‘")
    print(f"  - JSON: {PRODUCTS_JSON_PATH}")
    print(f"  - Vector DB: {VECTOR_DB_DIR}")

    # ê²½ë¡œ ìƒì„±
    VECTOR_DB_DIR.mkdir(parents=True, exist_ok=True)

    # Chroma í´ë¼ì´ì–¸íŠ¸
    client = chromadb.PersistentClient(path=str(VECTOR_DB_DIR))
    collection = client.get_or_create_collection(
        name="products",
        metadata={"hnsw:space": "cosine"},
    )

    # ìž„ë² ë”© ëª¨ë¸
    print(f"ðŸ§  ìž„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... ({EMBEDDING_MODEL_NAME})")
    emb_model = SentenceTransformer(EMBEDDING_MODEL_NAME)

    # JSON ë¡œë“œ
    with open(PRODUCTS_JSON_PATH, "r", encoding="utf-8") as f:
        products: List[Dict[str, Any]] = json.load(f)

    print(f"ðŸ“¦ ì´ ìƒí’ˆ ìˆ˜: {len(products)}ê°œ")

    ids: List[str] = []
    docs: List[str] = []
    metadatas: List[Dict[str, Any]] = []

    for p in products:
        product_id = p.get("product_id")
        category_id = p.get("category_id", "")
        brand_name = p.get("brand_name", "")
        product_name = p.get("product_name", "")
        price_str = p.get("price", "0")
        moods = p.get("mood_keywords", []) or []

        try:
            price_int = int(price_str)
        except Exception:
            price_int = 0

        # ìž„ë² ë”©ìš© í…ìŠ¤íŠ¸ êµ¬ì„±
        text_parts = [
            f"[ì¹´í…Œê³ ë¦¬] {category_id}",
            f"[ë¸Œëžœë“œ] {brand_name}",
            f"[ìƒí’ˆëª…] {product_name}",
            f"[ê°€ê²©] {price_str}ì›",
        ]
        if moods:
            text_parts.append("[ë¬´ë“œ í‚¤ì›Œë“œ] " + ", ".join(moods))

        # ë‚˜ì¤‘ì— OCRë¡œ ìƒí’ˆ ì„¤ëª… ë¶™ì¼ ìˆ˜ ìžˆìŒ
        # description_text = p.get("description_text", "")
        # if description_text:
        #     text_parts.append("[ìƒí’ˆ ì„¤ëª…] " + description_text)

        doc_text = "\n".join(text_parts)

        ids.append(product_id)
        docs.append(doc_text)
        metadatas.append(
            {
                "product_id": product_id,
                "category_id": category_id,
                "brand_name": brand_name,
                "price": price_int,
                "moods": moods,
                "link_url": p.get("link_url", ""),
                "image_url": p.get("image_url", ""),
                "source_site": infer_source_site(product_id),
            }
        )

    print("ðŸ§  ìž„ë² ë”© ê³„ì‚° ì¤‘...")
    embeddings = emb_model.encode(docs, batch_size=64, show_progress_bar=True)

    print("ðŸ’¾ Chroma ì»¬ë ‰ì…˜ì— ì¶”ê°€ ì¤‘...")
    collection.add(
        ids=ids,
        documents=docs,
        embeddings=embeddings,
        metadatas=metadatas,
    )

    print("âœ… ì¸ë±ì‹± ì™„ë£Œ!")


def infer_source_site(product_id: str) -> str:
    """
    product_id íŒ¨í„´ìœ¼ë¡œ ê°„ë‹¨ížˆ ì¶œì²˜ ë¶„ë¥˜
    ì˜ˆ: ten_..., kakao_..., guud_...
    """
    if product_id.startswith("ten_"):
        return "10x10"
    if product_id.startswith("kakao_"):
        return "kakao"
    if product_id.startswith("guud_"):
        return "guud"
    return "unknown"


if __name__ == "__main__":
    build_index()

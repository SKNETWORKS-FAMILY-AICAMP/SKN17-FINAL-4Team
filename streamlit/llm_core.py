# llm_core.py
"""
Qwen2.5-14B-Korean ê¸°ë°˜ LLM ëª¨ë“ˆ (8bit ì–‘ìí™” ë¡œë”©)

- ì¼ë°˜ ëŒ€í™” / ì¶”ì²œ ìƒì„±: chat_template.jinja í™œìš© (use_chat_template=True)
- JSON íŒŒì‹±(parse_user_query): í…œí”Œë¦¿ ì•ˆ ì“°ê³  ë‹¨ìˆœ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë§Œ í˜¸ì¶œ (use_chat_template=False)
"""

import json
import re
from typing import List, Tuple, Dict, Any

import torch
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
)

from config import HF_QWEN_MODEL_NAME


# =========================
# 1. ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# =========================

DEFAULT_SYSTEM_PROMPT = (
    "ë„ˆëŠ” ì¸í…Œë¦¬ì–´Â·í™ˆë°ì½” ìƒí’ˆ ì¶”ì²œì„ ë„ì™€ì£¼ëŠ” í•œêµ­ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤. "
    "ì‚¬ìš©ìì˜ ì·¨í–¥(ë¬´ë“œ, í†¤, ìŠ¤íƒ€ì¼), ì˜ˆì‚°, ê³µê°„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ "
    "ìƒí’ˆì„ ì¶”ì²œí•˜ê±°ë‚˜ ì¸í…Œë¦¬ì–´ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ì¤€ë‹¤. "
    "ì„¤ëª…ì€ ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ, í•˜ì§€ë§Œ ê³¼ì¥ ì—†ì´ í•´ë¼."
)


# =========================
# 2. ëª¨ë¸ ë¡œë”© (8bit)
# =========================

print(f"[LLM] â–¶ Qwen2.5-14B-Korean (8bit, device_map='auto') ë¡œë”© ì¤‘...")

bnb_config = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_threshold=6.0,
    llm_int8_has_fp16_weight=False,
)

tokenizer = AutoTokenizer.from_pretrained(
    HF_QWEN_MODEL_NAME,
    use_fast=True,
    trust_remote_code=True,
)

model = AutoModelForCausalLM.from_pretrained(
    HF_QWEN_MODEL_NAME,
    quantization_config=bnb_config,
    device_map="auto",
    trust_remote_code=True,
)

model.eval()


# =========================
# 3. ì¶œë ¥ í›„ì²˜ë¦¬: ëŠê¸´ ë¬¸ì¥ ì˜ë¼ë‚´ê¸°
# =========================

def clean_trailing_incomplete_sentence(text: str) -> str:
    """
    ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ì¤‘ê°„ì— ëŠê¸´ ê²½ìš°,
    ë§ˆì§€ë§‰ 'ì™„ì „í•œ ë¬¸ì¥'ê¹Œì§€ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ë¥¼ ì˜ë¼ë‚¸ë‹¤.

    - 1ì°¨: . ? ! â€¦ ë“± ë¬¸ì¥ ë êµ¬ë‘ì  ê¸°ì¤€
    - 2ì°¨: í•œêµ­ì–´ ì¢…ê²° ì–´ë¯¸(ìš”/í•©ë‹ˆë‹¤/ì…ë‹ˆë‹¤/ì˜ˆìš”/ì—ìš”/ê±°ì˜ˆìš”/ê±°ì—ìš” ë“±)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ê¸°
    - ë„ˆë¬´ ê³¼í•˜ê²Œ ì˜ë¦° ê²½ìš°(ì „ì²´ì˜ 50% ë¯¸ë§Œ)ì—ëŠ” ì›ë³¸ì„ ìœ ì§€
    """
    text = text.strip()
    if len(text) < 40:
        # ë„ˆë¬´ ì§§ì€ ë‹µë³€ì€ êµ³ì´ ì†ëŒ€ì§€ ì•ŠëŠ”ë‹¤.
        return text

    length = len(text)
    best_cut = -1

    # --- 1) êµ¬ë‘ì  ê¸°ì¤€ (., ?, !, â€¦ ë“±) ---
    enders = [".", "?", "!", "â€¦", "ã€‚", "ï¼", "ï¼Ÿ"]
    last_punc_idx = -1
    for ch in enders:
        idx = text.rfind(ch)
        if idx > last_punc_idx:
            last_punc_idx = idx

    if last_punc_idx != -1 and last_punc_idx > length * 0.3:
        best_cut = max(best_cut, last_punc_idx + 1)

    # --- 2) í•œêµ­ì–´ ì¢…ê²° ì–´ë¯¸ ê¸°ì¤€ ---
    # ì˜ˆ: "ì›í•˜ì‹œë‚˜ìš”,", "ì¢‹ì•„ìš”.", "ê´œì°®ìŠµë‹ˆë‹¤" ë“±ì—ì„œ ì¢…ê²° ì–´ë¯¸ ë¶€ë¶„ê¹Œì§€ë§Œ ì·¨í•¨
    # (, . ? ! ê³µë°± ë“± ë¹„-í•œê¸€ ë¬¸ìê°€ ë’¤ë”°ë¥´ëŠ” ìœ„ì¹˜ê¹Œì§€ í¬í•¨)
    ender_pattern = re.compile(
        r"(ìš”|ì…ë‹ˆë‹¤|í•©ë‹ˆë‹¤|ì˜ˆìš”|ì—ìš”|ê±°ì˜ˆìš”|ê±°ì—ìš”)(?=[^ê°€-í£]|$)"
    )

    last_match_end = -1
    for m in ender_pattern.finditer(text):
        end_pos = m.end(1)
        if end_pos > last_match_end:
            last_match_end = end_pos

    if last_match_end != -1 and last_match_end > length * 0.3:
        best_cut = max(best_cut, last_match_end)

    # ìë¥¼ ìœ„ì¹˜ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if best_cut == -1:
        return text

    cleaned = text[:best_cut].strip()

    # ë„ˆë¬´ ë§ì´ ì˜ë ¸ìœ¼ë©´(50% ë¯¸ë§Œ ë‚¨ìœ¼ë©´) ì›ë³¸ ìœ ì§€
    if len(cleaned) < length * 0.5:
        return text

    return cleaned


# =========================
# 4. ì…ë ¥ ë¹Œë”
# =========================

def _build_inputs_with_template(messages: List[Dict[str, str]]):
    """
    Qwen chat_template.jinja ë¥¼ ì‚¬ìš©í•œ ì…ë ¥ ìƒì„±
    (ì¼ë°˜ ëŒ€í™” / ì¶”ì²œ ì‘ë‹µìš©)
    """
    input_ids = tokenizer.apply_chat_template(
        messages,
        tokenize=True,
        add_generation_prompt=True,
        return_tensors="pt",
    )
    return {"input_ids": input_ids}


def _build_inputs_fallback(system_prompt: str, user_text: str):
    """
    chat_template ì—†ì´ ë‹¨ìˆœ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì…ë ¥ ìƒì„±
    (parse_user_queryìš©: ë²„ê·¸ íšŒí”¼ìš© ì•ˆì „ ê²½ë¡œ)
    """
    text = (
        f"[SYSTEM]\n{system_prompt}\n\n"
        f"[USER]\n{user_text}\n\n"
        "[ASSISTANT]\n"
    )
    enc = tokenizer(text, return_tensors="pt")
    return {"input_ids": enc["input_ids"]}


# =========================
# 5. ê³µí†µ chat í•¨ìˆ˜
# =========================

def chat(
    history: List[Tuple[str, str]],
    user_input: str,
    system_prompt: str = DEFAULT_SYSTEM_PROMPT,
    max_new_tokens: int = 512,
    temperature: float = 0.7,
    top_p: float = 0.9,
    do_sample: bool = True,
    use_chat_template: bool = True,
) -> str:
    """
    history: [(user, assistant), ...]
    user_input: ì´ë²ˆ í„´ ì‚¬ìš©ì ì…ë ¥ (í˜¹ì€ RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨ í”„ë¡¬í”„íŠ¸)

    - use_chat_template=True  â†’ Qwen chat_template ì‚¬ìš© (ì¼ë°˜ ëŒ€í™”/ì¶”ì²œ)
    - use_chat_template=False â†’ fallback í…ìŠ¤íŠ¸ í¬ë§· ì‚¬ìš© (íŒŒì„œ)
    """
    if use_chat_template:
        # ChatML í˜•ì‹ ì‚¬ìš©
        messages: List[Dict[str, str]] = []
        messages.append({"role": "system", "content": system_prompt})

        for q, a in history:
            messages.append({"role": "user", "content": q})
            messages.append({"role": "assistant", "content": a})

        messages.append({"role": "user", "content": user_input})

        inputs = _build_inputs_with_template(messages)
    else:
        # ë‹¨ìˆœ í…ìŠ¤íŠ¸ í¬ë§·
        inputs = _build_inputs_fallback(system_prompt, user_input)

    input_ids = inputs["input_ids"]
    attention_mask = torch.ones_like(input_ids)

    # ëª¨ë¸ì˜ ë©”ì¸ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
    main_device = next(model.parameters()).device
    input_ids = input_ids.to(main_device)
    attention_mask = attention_mask.to(main_device)

    gen_kwargs = dict(
        max_new_tokens=max_new_tokens,
        pad_token_id=tokenizer.eos_token_id,
    )

    if do_sample:
        gen_kwargs.update(
            do_sample=True,
            temperature=float(temperature),
            top_p=float(top_p),
        )
    else:
        gen_kwargs.update(
            do_sample=False,
        )

    with torch.no_grad():
        outputs = model.generate(
            input_ids=input_ids,
            attention_mask=attention_mask,
            **gen_kwargs,
        )

    input_len = input_ids.shape[1]
    generated_ids = outputs[0][input_len:]

    text = tokenizer.decode(generated_ids, skip_special_tokens=True)
    text = text.strip()

    # ğŸ”¹ ë§ì´ ì• ë§¤í•˜ê²Œ ëŠê¸´ ê²½ìš°, ë§ˆì§€ë§‰ ì™„ì „í•œ ë¬¸ì¥ê¹Œì§€ë§Œ ë‚¨ê¸°ê¸°
    text = clean_trailing_incomplete_sentence(text)

    return text


# =========================
# 6. ì‚¬ìš©ì ì§ˆì˜ íŒŒì‹± (ì¹´í…Œê³ ë¦¬/ë¬´ë“œ/ì˜ˆì‚°)
# =========================

def parse_user_query(user_text: str) -> Dict[str, Any]:
    """
    Qwenì—ê²Œ í•œ ë²ˆ ë¬¼ì–´ì„œ:
    - category: "ëŸ¬ê·¸", "ì»¤íŠ¼", "ì¡°ëª…", "ìˆ˜ë‚©ì¥" ë“± (ì—†ìœ¼ë©´ null)
    - price_min / price_max: ì› ë‹¨ìœ„ ì •ìˆ˜ (ì—†ìœ¼ë©´ null)
    - moods: ["ì•„ëŠ‘í•œ", "ìš°ë“œí†¤", "ëª¨ë˜", ...] ë¦¬ìŠ¤íŠ¸
    - space: ì‚¬ìš©ìê°€ ê¾¸ë¯¸ê³  ì‹¶ë‹¤ê³  ë§í•œ ì£¼ìš” ê³µê°„ (ì˜ˆ: "ì±…ìƒ ê·¼ì²˜", "ì¹¨ì‹¤", "ê±°ì‹¤" ë“±)

    âš ï¸ ì—¬ê¸°ì„œëŠ” chat_template ì‚¬ìš© ì•ˆ í•¨ (HF ìª½ ë²„ê·¸ íšŒí”¼ìš©)
    """
    parse_system_prompt = (
        "ë„ˆëŠ” ì¸í…Œë¦¬ì–´ ìƒí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œì˜ íŒŒì„œ(parser)ì´ë‹¤. "
        "ì‚¬ìš©ìì˜ í•œêµ­ì–´ ë¬¸ì¥ì„ ì½ê³  ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶”ì¶œí•´ë¼.\n\n"
        'í•„ë“œ ì„¤ëª…:\n'
        '  - "category": ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì£¼ìš” ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "ëŸ¬ê·¸", "ì»¤íŠ¼", "ì¡°ëª…", "ìˆ˜ë‚©ì¥"). ì—†ìœ¼ë©´ null.\n'
        '  - "price_min": ì˜ˆì‚°ì˜ ìµœì†Œê°’ (ì› ë‹¨ìœ„ ì •ìˆ˜). ì—†ìœ¼ë©´ null.\n'
        '  - "price_max": ì˜ˆì‚°ì˜ ìµœëŒ€ê°’ (ì› ë‹¨ìœ„ ì •ìˆ˜). ì—†ìœ¼ë©´ null.\n'
        '  - "moods": ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë¬´ë“œ/ë¶„ìœ„ê¸°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í•œêµ­ì–´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ '
        '             (ì˜ˆ: ["ì•„ëŠ‘í•œ", "ë”°ëœ»í•œ", "ë¯¸ë‹ˆë©€", "ìš°ë“œí†¤"]).\n'
        '  - "space": ì‚¬ìš©ìê°€ ê¾¸ë¯¸ê³  ì‹¶ë‹¤ê³  ë§í•œ ì£¼ìš” ê³µê°„. '
        '             ì˜ˆ: "ì±…ìƒ ê·¼ì²˜", "ì¹¨ì‹¤", "ê±°ì‹¤", "ì‘ì—…ì‹¤", "ì„œì¬", "ì¹¨ëŒ€ ì˜†" ë“±. ì—†ìœ¼ë©´ null.\n\n'
        "ì¤‘ìš” ê·œì¹™:\n"
        "1) ë¬´ë“œ(moods)ì—ëŠ” 'ì•„ëŠ‘í•œ', 'ë”°ëœ»í•œ', 'ë¯¸ë‹ˆë©€', 'ëª¨ë˜', 'ë¶ìœ ëŸ½í’'ì²˜ëŸ¼ ë¶„ìœ„ê¸°/ìŠ¤íƒ€ì¼ì„ ë‚˜íƒ€ë‚´ëŠ” í˜•ìš©ì‚¬/í˜•ìš©ì‚¬êµ¬ë§Œ ë„£ì–´ë¼.\n"
        "2) 'ì±…ìƒ ê·¼ì²˜', 'ì¹¨ì‹¤', 'ê±°ì‹¤', 'ì‘ì—…ì‹¤', 'ì„œì¬', 'ë°© í•œ êµ¬ì„' ê°™ì´ 'ê³µê°„/ìœ„ì¹˜'ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ì€ "
        "moodsì— ë„£ì§€ ë§ê³  ë°˜ë“œì‹œ space í•„ë“œì— ë„£ì–´ë¼.\n"
        "3) ì‚¬ìš©ìê°€ ì—¬ëŸ¬ ê³µê°„ì„ ë§í•˜ë”ë¼ë„ ê°€ì¥ ì¤‘ì‹¬ì´ ë˜ëŠ” í•œ ê³³ë§Œ spaceì— ë„£ì–´ë¼.\n"
        "4) ê°€ê²©ì€ '10ë§Œì›', '5~7ë§Œì›', '20ë§Œ ì› ì´í•˜' ê°™ì€ í‘œí˜„ì„ ì ì ˆíˆ í•´ì„í•´ë¼. "
        "ì˜ˆì‚°ì´ ì „í˜€ ì–¸ê¸‰ë˜ì§€ ì•Šìœ¼ë©´ price_min, price_maxëŠ” ëª¨ë‘ nullë¡œ ë‘”ë‹¤.\n"
        "5) JSON ì´ì™¸ì˜ ê¸€ìëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼."
    )

    parse_user_prompt = (
        f"ì‚¬ìš©ì ì…ë ¥: {user_text}\n\n"
        "ìœ„ ì„¤ëª…ëŒ€ë¡œ JSONë§Œ ì¶œë ¥í•´."
    )

    raw = chat(
        history=[],
        user_input=parse_user_prompt,
        system_prompt=parse_system_prompt,
        max_new_tokens=256,
        temperature=0.7,   # do_sample=Falseë¼ ì‹¤ì œë¡œëŠ” ì‚¬ìš© ì•ˆ ë¨
        top_p=1.0,
        do_sample=False,   # íŒŒì„œëŠ” ê²°ì •ì ìœ¼ë¡œ
        use_chat_template=False,  # ğŸ”´ í…œí”Œë¦¿ ì‚¬ìš© ê¸ˆì§€ (ë²„ê·¸ íšŒí”¼)
    )

    # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
    match = re.search(r"\{.*\}", raw, re.DOTALL)
    if not match:
        return {
            "category": None,
            "price_min": None,
            "price_max": None,
            "moods": [],
            "space": None,
        }

    json_str = match.group(0)

    try:
        data = json.loads(json_str)
    except Exception:
        return {
            "category": None,
            "price_min": None,
            "price_max": None,
            "moods": [],
            "space": None,
        }

    category = data.get("category")
    price_min = data.get("price_min")
    price_max = data.get("price_max")
    moods = data.get("moods") or []
    space = data.get("space")

    # moods ì •ì œ
    if isinstance(moods, str):
        moods = [m.strip() for m in moods.split(",") if m.strip()]
    elif isinstance(moods, list):
        moods = [str(m).strip() for m in moods if str(m).strip()]
    else:
        moods = []

    def _to_int_or_none(x):
        if x is None:
            return None
        if isinstance(x, (int, float)):
            return int(x)
        s = str(x).replace(",", "").replace(" ", "")
        if s.isdigit():
            return int(s)
        return None

    price_min = _to_int_or_none(price_min)
    price_max = _to_int_or_none(price_max)

    return {
        "category": category or None,
        "price_min": price_min,
        "price_max": price_max,
        "moods": moods,
        "space": space or None,
    }

